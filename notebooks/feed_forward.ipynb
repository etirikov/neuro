{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mens = []\n",
    "womens = []\n",
    "labels = pd.read_csv('./gender_labels.csv')\n",
    "for s in glob.glob('/neuro/notebooks/all_data_confounds_remove/*.csv'):\n",
    "    person = int(s.split('/')[-1].split('_')[0])\n",
    "    data = pd.read_csv(s)\n",
    "    data = data.rolling(window=10).mean().dropna()\n",
    "    if labels[labels['person']==person]['gender'].values[0]=='M':\n",
    "        mens.append(data)\n",
    "    else:\n",
    "        womens.append(data)\n",
    "mens = pd.concat(mens)\n",
    "womens = pd.concat(womens)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147684"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../notebooks/filter_with_confounds_dataset.csv')\n",
    "# data = mens\n",
    "# region = 'x1'\n",
    "# X = data.drop([region], axis=1).values\n",
    "# y = data[region].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147684, 48)\n",
      "x34\n",
      "Iteration: 0\n",
      "train: -477.0328144104164\n",
      "test: -478.84249911189795\n",
      "train: 0.22226559049493302\n",
      "test: 0.22477303787910452\n",
      "Iteration: 1000\n",
      "train: 0.677063859347943\n",
      "test: 0.4500079486015237\n",
      "train: 0.04709342702340032\n",
      "test: 0.07959051970703594\n",
      "Iteration: 2000\n",
      "train: 0.686387049780744\n",
      "test: 0.4184319022095211\n",
      "train: 0.04532878407023519\n",
      "test: 0.08347626172304999\n",
      "Iteration: 3000\n",
      "train: 0.6918307499017923\n",
      "test: 0.4005312364471554\n",
      "train: 0.04516921049882837\n",
      "test: 0.08729954453206014\n",
      "Iteration: 4000\n",
      "train: 0.684349267471236\n",
      "test: 0.3854981311320129\n",
      "train: 0.04533310232215577\n",
      "test: 0.0878788789113663\n",
      "Iteration: 5000\n",
      "train: 0.6580932678215812\n",
      "test: 0.3363455593246918\n",
      "train: 0.04566660172395683\n",
      "test: 0.08802558716969354\n",
      "Iteration: 6000\n",
      "train: 0.6916765407815615\n",
      "test: 0.3827279052984418\n",
      "train: 0.044855138451940446\n",
      "test: 0.0891251358106201\n",
      "Iteration: 7000\n",
      "train: 0.6999059637113312\n",
      "test: 0.3845728647402309\n",
      "train: 0.043948724946570886\n",
      "test: 0.08972106019069073\n",
      "Iteration: 8000\n",
      "train: 0.7082329225775494\n",
      "test: 0.3907229347642771\n",
      "train: 0.043231878458753294\n",
      "test: 0.0897286946266387\n",
      "Iteration: 9000\n",
      "train: 0.697566345320486\n",
      "test: 0.38109547030370394\n",
      "train: 0.04425379379297959\n",
      "test: 0.08984080618736245\n",
      "x35\n",
      "Iteration: 0\n",
      "train: -2.0046043817697177\n",
      "test: -1.9959196617999173\n",
      "train: 0.27782428799009634\n",
      "test: 0.2785845836040092\n",
      "Iteration: 1000\n",
      "train: 0.9065421747884079\n",
      "test: 0.8507292589792176\n",
      "train: 0.03714728151936661\n",
      "test: 0.059194207658504534\n",
      "Iteration: 2000\n",
      "train: 0.9114259482342886\n",
      "test: 0.8456809945753145\n",
      "train: 0.035782471840790364\n",
      "test: 0.0624412952159647\n",
      "Iteration: 3000\n",
      "train: 0.9107390894245408\n",
      "test: 0.8398289628586644\n",
      "train: 0.03599982093884989\n",
      "test: 0.0646207792097825\n",
      "Iteration: 4000\n",
      "train: 0.9079900648737808\n",
      "test: 0.8333023743638264\n",
      "train: 0.03671864474943354\n",
      "test: 0.06645607357175302\n",
      "Iteration: 5000\n",
      "train: 0.9135403271760054\n",
      "test: 0.8348940484459763\n",
      "train: 0.03513993297036684\n",
      "test: 0.0671723463804514\n",
      "Iteration: 6000\n",
      "train: 0.9155476175090442\n",
      "test: 0.8379565253419883\n",
      "train: 0.03441193785835654\n",
      "test: 0.06628357047196058\n",
      "Iteration: 7000\n",
      "train: 0.9158356773245742\n",
      "test: 0.8345986523408786\n",
      "train: 0.03360020273280609\n",
      "test: 0.06632904029707751\n",
      "Iteration: 8000\n",
      "train: 0.9153094842251089\n",
      "test: 0.8360142795603236\n",
      "train: 0.03433106628108136\n",
      "test: 0.06674645921272948\n",
      "Iteration: 9000\n",
      "train: 0.9162084579850236\n",
      "test: 0.835756470518171\n",
      "train: 0.034028627906305085\n",
      "test: 0.06702796697079381\n",
      "x36\n",
      "Iteration: 0\n",
      "train: -194.19186263580377\n",
      "test: -195.02876627739906\n",
      "train: 0.15039747982004525\n",
      "test: 0.14986489267549372\n",
      "Iteration: 1000\n",
      "train: 0.5647557262696694\n",
      "test: 0.2850026262297146\n",
      "train: 0.0436302451219885\n",
      "test: 0.07193596817955876\n",
      "Iteration: 2000\n",
      "train: 0.564041415240677\n",
      "test: 0.2346589350927768\n",
      "train: 0.043066446283405446\n",
      "test: 0.07565975168173585\n",
      "Iteration: 3000\n",
      "train: 0.6121294735680507\n",
      "test: 0.2665180027121863\n",
      "train: 0.04138437491611538\n",
      "test: 0.07847861797344552\n",
      "Iteration: 4000\n",
      "train: 0.6248761943120282\n",
      "test: 0.24757718989110933\n",
      "train: 0.039845116497097786\n",
      "test: 0.08022303531135284\n",
      "Iteration: 5000\n",
      "train: 0.6285950068526763\n",
      "test: 0.25030357088236677\n",
      "train: 0.03990609316841737\n",
      "test: 0.08093384811706919\n",
      "Iteration: 6000\n",
      "train: 0.6339455121151322\n",
      "test: 0.24481828280889661\n",
      "train: 0.03909452266300696\n",
      "test: 0.081263770818743\n",
      "Iteration: 7000\n",
      "train: 0.6291353476151493\n",
      "test: 0.24644560589561726\n",
      "train: 0.039983583614995835\n",
      "test: 0.08155601591862593\n",
      "Iteration: 8000\n",
      "train: 0.6269721539248454\n",
      "test: 0.24008790021323767\n",
      "train: 0.039873396479424596\n",
      "test: 0.08186141625953945\n",
      "Iteration: 9000\n",
      "train: 0.6186730466070413\n",
      "test: 0.22369345428218979\n",
      "train: 0.039704131279209215\n",
      "test: 0.08165760221966654\n",
      "x37\n",
      "Iteration: 0\n",
      "train: -59.74675277411659\n",
      "test: -61.140420870265224\n",
      "train: 0.17461980236281155\n",
      "test: 0.1767624590935771\n",
      "Iteration: 1000\n",
      "train: 0.7142286165205747\n",
      "test: 0.5154422686619959\n",
      "train: 0.041639189425531443\n",
      "test: 0.07017213204516425\n",
      "Iteration: 2000\n",
      "train: 0.7368331007371416\n",
      "test: 0.5167193388672144\n",
      "train: 0.040675204661236156\n",
      "test: 0.07443282296717856\n",
      "Iteration: 3000\n",
      "train: 0.7414028435097287\n",
      "test: 0.5085898229166506\n",
      "train: 0.04030567589390677\n",
      "test: 0.07597778466096783\n",
      "Iteration: 4000\n",
      "train: 0.7371272076359561\n",
      "test: 0.4887348383689025\n",
      "train: 0.04004520234331193\n",
      "test: 0.07747444570233175\n",
      "Iteration: 5000\n",
      "train: 0.7471509972561499\n",
      "test: 0.4958651876828639\n",
      "train: 0.039432248683152184\n",
      "test: 0.07832150641245234\n",
      "Iteration: 6000\n",
      "train: 0.7439108163325701\n",
      "test: 0.4835658446266401\n",
      "train: 0.039197357687314714\n",
      "test: 0.07885146815920117\n",
      "Iteration: 7000\n",
      "train: 0.7386227060079275\n",
      "test: 0.4778963379864254\n",
      "train: 0.040003664262348325\n",
      "test: 0.07992951367653482\n",
      "Iteration: 8000\n",
      "train: 0.7338939138128733\n",
      "test: 0.4653781308037771\n",
      "train: 0.03955811853662175\n",
      "test: 0.07934232628326551\n",
      "Iteration: 9000\n",
      "train: 0.7352434829425705\n",
      "test: 0.4694881975286581\n",
      "train: 0.03950533019602994\n",
      "test: 0.07906577792957876\n",
      "x38\n",
      "Iteration: 0\n",
      "train: -257.29938313235994\n",
      "test: -256.46350221160145\n",
      "train: 0.3355036607887524\n",
      "test: 0.3311481362630179\n",
      "Iteration: 1000\n",
      "train: 0.8431131950372702\n",
      "test: 0.7455039560644009\n",
      "train: 0.045784101179068816\n",
      "test: 0.07367562470624749\n",
      "Iteration: 2000\n",
      "train: 0.8496897539145888\n",
      "test: 0.7294612900618154\n",
      "train: 0.04387680635326409\n",
      "test: 0.07849091704949987\n",
      "Iteration: 3000\n",
      "train: 0.8498819619314868\n",
      "test: 0.7222343915969375\n",
      "train: 0.04374964550454028\n",
      "test: 0.08076198232934571\n",
      "Iteration: 4000\n",
      "train: 0.8531299635341584\n",
      "test: 0.7191476424564629\n",
      "train: 0.0429987067585648\n",
      "test: 0.08204234138108435\n",
      "Iteration: 5000\n",
      "train: 0.8506461034251122\n",
      "test: 0.7149616390559497\n",
      "train: 0.043605980245464915\n",
      "test: 0.08291935537507122\n",
      "Iteration: 6000\n",
      "train: 0.8437009560165009\n",
      "test: 0.7068140008699391\n",
      "train: 0.044319554827674815\n",
      "test: 0.08302509747351985\n",
      "Iteration: 7000\n",
      "train: 0.8516355393018196\n",
      "test: 0.7070767329236343\n",
      "train: 0.04291497018599836\n",
      "test: 0.08429535222488838\n",
      "Iteration: 8000\n",
      "train: 0.8529437190592822\n",
      "test: 0.7100102035610656\n",
      "train: 0.04284639799794264\n",
      "test: 0.08429135773272287\n",
      "Iteration: 9000\n",
      "train: 0.855125668356887\n",
      "test: 0.7080209287239762\n",
      "train: 0.04234502446358474\n",
      "test: 0.08494603955503373\n",
      "x39\n",
      "Iteration: 0\n",
      "train: -51.17239324280318\n",
      "test: -52.48967086491805\n",
      "train: 0.4230347660098205\n",
      "test: 0.43253085878969494\n",
      "Iteration: 1000\n",
      "train: 0.8988918696511585\n",
      "test: 0.8363054794985879\n",
      "train: 0.04408865142548591\n",
      "test: 0.07228708206093654\n",
      "Iteration: 2000\n",
      "train: 0.899895879022024\n",
      "test: 0.8255993538472007\n",
      "train: 0.04374173661015621\n",
      "test: 0.07717789556050793\n",
      "Iteration: 3000\n",
      "train: 0.9044835116733204\n",
      "test: 0.8226783859619904\n",
      "train: 0.042430485141546646\n",
      "test: 0.07991280073167442\n",
      "Iteration: 4000\n",
      "train: 0.904129771407447\n",
      "test: 0.8192512493455666\n",
      "train: 0.042983677269386164\n",
      "test: 0.08248092384101102\n",
      "Iteration: 5000\n",
      "train: 0.9043648367331861\n",
      "test: 0.8183619307193308\n",
      "train: 0.042025949461977255\n",
      "test: 0.08073786161356362\n",
      "Iteration: 6000\n",
      "train: 0.9037335943630205\n",
      "test: 0.8132239455376411\n",
      "train: 0.041752030229019584\n",
      "test: 0.08191697191420298\n",
      "Iteration: 7000\n",
      "train: 0.9064768389277333\n",
      "test: 0.818911353756425\n",
      "train: 0.041945588410114365\n",
      "test: 0.08208828722275574\n",
      "Iteration: 8000\n",
      "train: 0.9031951477953531\n",
      "test: 0.8156064036805146\n",
      "train: 0.0429618626036876\n",
      "test: 0.08262326350053575\n",
      "Iteration: 9000\n",
      "train: 0.9061931651813318\n",
      "test: 0.8161165057787745\n",
      "train: 0.04152387632032758\n",
      "test: 0.08226134580204802\n",
      "x40\n",
      "Iteration: 0\n",
      "train: -32.132552060589894\n",
      "test: -31.859916475874478\n",
      "train: 0.34104225882577943\n",
      "test: 0.3398088291655651\n",
      "Iteration: 1000\n",
      "train: 0.8668251869411825\n",
      "test: 0.7833748527629657\n",
      "train: 0.047107351119226384\n",
      "test: 0.0759600805505916\n",
      "Iteration: 2000\n",
      "train: 0.8655701600613391\n",
      "test: 0.7698700484315236\n",
      "train: 0.04818588080987981\n",
      "test: 0.08193398699778182\n",
      "Iteration: 3000\n",
      "train: 0.8737864060152428\n",
      "test: 0.7703486514962374\n",
      "train: 0.04536332018447208\n",
      "test: 0.08206275827374783\n",
      "Iteration: 4000\n",
      "train: 0.8766265665754382\n",
      "test: 0.7717444817943748\n",
      "train: 0.046467812158748546\n",
      "test: 0.08574440833564631\n",
      "Iteration: 5000\n",
      "train: 0.8730356087650949\n",
      "test: 0.7619336911204677\n",
      "train: 0.04536319100032593\n",
      "test: 0.08479679304361337\n",
      "Iteration: 6000\n",
      "train: 0.8747174785631138\n",
      "test: 0.7628232927192957\n",
      "train: 0.044958952377379124\n",
      "test: 0.08479114100566822\n",
      "Iteration: 7000\n",
      "train: 0.8762063280170346\n",
      "test: 0.7629591945920224\n",
      "train: 0.04469800104565603\n",
      "test: 0.08541728253770128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8000\n",
      "train: 0.8759470939573573\n",
      "test: 0.7600743914161987\n",
      "train: 0.044522060104898974\n",
      "test: 0.08605699281855704\n",
      "Iteration: 9000\n",
      "train: 0.8793246061029493\n",
      "test: 0.7622569006178777\n",
      "train: 0.043632790733763326\n",
      "test: 0.08592901752754432\n"
     ]
    }
   ],
   "source": [
    "loses_by_epoch = {}\n",
    "data = mens\n",
    "print(data.shape)\n",
    "for i in range(34, 41):\n",
    "    region = 'x'+str(i)\n",
    "    print(region)\n",
    "    loses_by_epoch[region] = list()\n",
    "    X = data.drop([region], axis=1).values\n",
    "    y = data[region].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "\n",
    "    device='cuda:1'\n",
    "    X_train_torch = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_torch = torch.FloatTensor(y_train).to(device)\n",
    "\n",
    "    X_test_torch = torch.FloatTensor(X_test).to(device)\n",
    "    y_test_torch = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(47, 100),\n",
    "        torch.nn.Softplus(),\n",
    "        torch.nn.Linear(100, 50),\n",
    "        torch.nn.Softplus(),\n",
    "        torch.nn.Linear(50, 25),\n",
    "        torch.nn.Tanh(),\n",
    "        torch.nn.Linear(25, 1),\n",
    "    ).to(device)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    learning_rate = 1e-2\n",
    "    batch_size = 8096\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for t in range(10000):\n",
    "        for batch in range(0, X_train.shape[0], batch_size):\n",
    "\n",
    "            y_pred_train = model(X_train_torch[batch:batch+batch_size])\n",
    "\n",
    "\n",
    "            loss_train = loss_fn(y_pred_train, y_train_torch.reshape(-1, 1)[batch:batch+batch_size])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_predict = model(X_train_torch).detach().cpu().numpy()\n",
    "        test_predict = model(X_test_torch).detach().cpu().numpy()\n",
    "        r2_train = r2_score(np.ravel(train_predict), np.ravel(y_train))\n",
    "        r2_test = r2_score(np.ravel(test_predict), np.ravel(y_test))\n",
    "        mse_train = mean_squared_error(np.ravel(train_predict), np.ravel(y_train))\n",
    "        mse_test = mean_squared_error(np.ravel(test_predict), np.ravel(y_test))\n",
    "        loses_by_epoch[region].append([r2_train, r2_test, mse_train, mse_test])\n",
    "        if t%1000==0:\n",
    "            print('Iteration:',t)\n",
    "            print('train:',r2_score(np.ravel(train_predict), np.ravel(y_train)))\n",
    "            print('test:',r2_score(np.ravel(test_predict), np.ravel(y_test)))\n",
    "            print('train:',mean_squared_error(np.ravel(train_predict), np.ravel(y_train)))\n",
    "            print('test:',mean_squared_error(np.ravel(test_predict), np.ravel(y_test)))\n",
    "    torch.save(model.state_dict(), './models/pytorch_model_{0}_mens.pt'.format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
