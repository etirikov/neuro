{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from gplearn.genetic import SymbolicRegressor, SymbolicTransformer\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.utils import check_random_state\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mens = []\n",
    "womens = []\n",
    "labels = pd.read_csv('./gender_labels.csv')\n",
    "for s in glob.glob('/neuro/notebooks/all_data_confounds_remove/*.csv'):\n",
    "    person = int(s.split('/')[-1].split('_')[0])\n",
    "    data = pd.read_csv(s)\n",
    "    data = data.rolling(window=10).mean().dropna()\n",
    "    if labels[labels['person']==person]['gender'].values[0]=='M':\n",
    "        mens.append(data)\n",
    "    else:\n",
    "        womens.append(data)\n",
    "mens = pd.concat(mens)\n",
    "womens = pd.concat(womens)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../notebooks/filter_with_confounds_dataset.csv')\n",
    "region = 'x13'\n",
    "X = data.drop([region], axis=1)\n",
    "X = 10*X\n",
    "feature_names = X.columns\n",
    "feature_names = data.drop([region], axis=1).columns\n",
    "y = data[region].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0 12397.87     1.65116e+105    54409         0.248561         0.250694   1615.30m\n",
      "   1  4614.18      2.18591e+62        3         0.248168         0.254233   1144.40m\n",
      "   2  1250.27      1.47316e+08        3         0.247826         0.257316   1068.95m\n",
      "   3   634.26      2.67949e+06        4         0.247413         0.261033    318.96m\n",
      "   4   155.03      3.83946e+08        3         0.247617         0.259193    173.26m\n",
      "   5     5.95      5.12237e+28        3         0.247473         0.260487     57.06m\n",
      "   6     3.49      1.17432e+06        3         0.247447          0.26072     15.39m\n",
      "   7     3.39      5.54371e+07        3         0.247406          0.26109     15.08m\n",
      "   8     3.43          42245.4        3         0.247114         0.263717     15.84m\n",
      "   9     3.09          870.444        3         0.247368         0.261429     18.08m\n",
      "  10     3.73      2.83805e+12        3         0.247435          0.26083     16.11m\n",
      "  11     3.39           146992        3          0.24769         0.258533     15.28m\n",
      "  12     3.37          5179.64        3         0.246885         0.265778     16.07m\n",
      "  13     3.41      1.42177e+19        3         0.247596         0.259384     14.58m\n",
      "  14     3.71      5.26735e+06        3         0.247476         0.260458     14.92m\n",
      "  15     3.39          43334.3        3         0.247626         0.259115     15.57m\n",
      "  16     4.13           160924        3          0.24729         0.262132     17.68m\n",
      "  17     4.36          9610.07        5         0.247302         0.262025     18.94m\n",
      "  18     3.68      8.87281e+06        3         0.247441         0.260777     18.94m\n",
      "  19     3.54          13056.9        3         0.247489         0.260344     14.80m\n",
      "  20     3.68          1722.53        4         0.247155         0.263347     17.20m\n",
      "  21     3.68          12657.2        3         0.247378         0.261343     14.86m\n",
      "  22     4.07      5.54874e+14        3         0.247295         0.262089     14.27m\n",
      "  23     3.68          4055.15        3         0.247481         0.260418     14.44m\n",
      "  24     4.18       8.7363e+14        4         0.247289         0.262144     14.19m\n",
      "  25     4.02          73925.4        4         0.247502         0.260225     15.01m\n",
      "  26     5.46      9.46142e+07        3         0.247313          0.26193     16.07m\n",
      "  27     3.79      1.02236e+11        3         0.247545         0.259836     14.64m\n",
      "  28     3.73          7475.53        3         0.247444         0.260746     14.88m\n",
      "  29    38.36      3.26693e+07        3         0.247468         0.260537     49.03m\n",
      "  30     3.98      2.64347e+07        3         0.247453         0.260665     15.90m\n",
      "  31     3.96      7.37483e+08        3         0.247553         0.259766     14.07m\n",
      "  32     4.68      1.59378e+09        3         0.247385         0.261284     16.62m\n",
      "  33     3.75      4.32568e+09        3         0.247243          0.26256     14.49m\n",
      "  34     3.79      1.10243e+06        4         0.247383         0.261301     14.93m\n",
      "  35     6.00           777755        3          0.24706         0.264204     17.21m\n",
      "  36     3.63          1826.19        5         0.247398         0.261165     14.42m\n",
      "  37     3.88      7.48018e+08        3         0.247455          0.26065     15.07m\n",
      "  38     3.67          15365.1        3         0.247471         0.260503     13.22m\n",
      "  39     3.90      1.18555e+08        3         0.247375         0.261371     14.24m\n",
      "  40     4.50           620172        3         0.247082         0.264004     15.50m\n",
      "  41     4.19      2.26757e+06        4         0.247279         0.262239     17.02m\n",
      "  42     3.85          10763.9        4         0.247116         0.263705     13.07m\n",
      "  43    11.48          32650.4        3         0.247427         0.260901     19.21m\n",
      "  44     5.65      3.58144e+13        3         0.247175         0.263169     16.84m\n",
      "  45     4.20           346748        6         0.247304         0.262007     12.92m\n",
      "  46     4.12          97351.7        4         0.247356         0.261542     15.03m\n",
      "  47     5.02      3.75306e+09        3         0.247302         0.262026     13.87m\n",
      "  48     3.91          15654.4        4         0.247358         0.261522     13.74m\n",
      "  49     4.46           493408        4         0.247182         0.263107     12.90m\n",
      "  50     4.77      1.92968e+06        5         0.247449         0.260704     14.20m\n",
      "  51     4.31           407113        6         0.247037          0.26441     16.27m\n",
      "  52     4.43      1.85235e+09        4         0.246857         0.266032     15.50m\n",
      "  53     4.56      8.55648e+06        3          0.24753         0.259975     17.60m\n",
      "  54     4.05           933.17        4         0.247435         0.260833     14.60m\n",
      "  55     4.76      5.32958e+12        3         0.247384         0.261292     13.56m\n",
      "  56     4.43      3.96547e+11        3          0.24751         0.260151     13.15m\n",
      "  57     4.35      5.61846e+07        3         0.247314         0.261923     14.88m\n",
      "  58     5.18      9.81276e+09        3         0.247261         0.262399     13.73m\n",
      "  59     4.07        4.974e+09        3         0.247185         0.263082     13.74m\n",
      "  60     4.17      1.59287e+06        3         0.247454         0.260656     11.95m\n",
      "  61     3.43          11663.1        3         0.247641         0.258981     13.31m\n",
      "  62     3.82      1.40809e+20        4         0.247024         0.264527     12.98m\n",
      "  63    13.44      5.10413e+06        3         0.247087         0.263966     19.04m\n",
      "  64     3.37          2292.17        3         0.247133         0.263548     12.27m\n",
      "  65     3.40          5048.81        3         0.247373         0.261392     11.00m\n",
      "  66     3.59          76276.4        3         0.247507         0.260181     10.64m\n",
      "  67     3.61      8.79739e+06        3         0.247262         0.262386     11.63m\n",
      "  68     3.52      6.19095e+07        4         0.247265         0.262358     10.70m\n",
      "  69     3.55          596.392        4         0.247378         0.261342     11.27m\n",
      "  70     3.63          46741.4        4         0.247233         0.262645     11.43m\n",
      "  71     3.48          3106.42        3         0.247445         0.260742     10.45m\n",
      "  72     4.17          1141.28        4         0.247381         0.261316     10.86m\n",
      "  73     3.90          7495.91        3         0.246853         0.266068     10.14m\n",
      "  74     4.28      1.48324e+07        3         0.247382         0.261311     12.64m\n",
      "  75     3.77      1.64384e+09        3          0.24743         0.260878     11.16m\n",
      "  76     3.56      4.71506e+06        6          0.24721         0.262854     12.31m\n",
      "  77     3.77      3.35087e+07        3         0.247362         0.261485     12.77m\n",
      "  78     4.68      3.31574e+08        3         0.247582         0.259505     12.49m\n",
      "  79     4.23      2.70497e+09        3         0.247163         0.263274     10.10m\n",
      "  80     3.59          11926.4        3          0.24713         0.263578     10.67m\n",
      "  81     3.66          53333.3        3         0.247547         0.259826     10.00m\n",
      "  82     3.83          9274.71        3         0.247097         0.263872      9.52m\n",
      "  83     3.56          553.599        4         0.247494         0.260296      9.42m\n",
      "  84     5.10      4.27731e+17        4         0.247285         0.262178      9.90m\n",
      "  85     5.48      1.09461e+23        4         0.247633         0.259047     10.32m\n",
      "  86     3.69          4394.87        3         0.247008         0.264671      9.55m\n",
      "  87     3.95           121239        4         0.247078         0.264039      9.53m\n",
      "  88     4.13          5613.51        4         0.247128         0.263596     10.07m\n",
      "  89     4.05          20411.9        3         0.247563         0.259678     10.47m\n",
      "  90     3.78          19681.3        4         0.246998          0.26476     10.22m\n",
      "  91     3.71      4.68209e+06        3         0.247583         0.259499     11.36m\n",
      "  92     4.30      2.89272e+08        3         0.247392         0.261218      9.40m\n",
      "  93     3.75      4.38622e+07        3         0.247492         0.260321      8.90m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  94     4.33      7.77857e+08        3         0.247306         0.261987     10.03m\n",
      "  95     3.84          24492.2        3         0.247374         0.261378      8.52m\n",
      "  96     3.65       1.4345e+06        3         0.247351         0.261588      9.45m\n",
      "  97     5.07       1.4148e+10        4         0.247253          0.26247      9.01m\n",
      "  98     4.28      2.71572e+06        3         0.247333         0.261749      8.49m\n",
      "  99     4.87      3.03841e+08        3         0.247291          0.26213      8.92m\n",
      " 100     3.52          7172.83        3          0.24734         0.261685      7.97m\n",
      " 101     3.41          10735.9        4         0.247429         0.260887      7.75m\n",
      " 102     3.44          298.086        3         0.247188          0.26305      7.79m\n",
      " 103     4.38      1.30251e+08        3         0.247236         0.262617      9.27m\n",
      " 104     3.63       3.7324e+13        4         0.247576          0.25956      7.87m\n",
      " 105     3.56      8.29786e+07        3         0.247152         0.263375      8.16m\n",
      " 106     3.57      2.23911e+10        3         0.247434         0.260835      7.47m\n",
      " 107     3.74      8.07111e+10        4         0.247546         0.259828      9.21m\n",
      " 108     3.93      1.17156e+12        3         0.247625         0.259119      8.66m\n",
      " 109     3.56      1.49122e+08        3         0.246681         0.267619      7.09m\n",
      " 110     3.92          87853.1        3         0.247272           0.2623      7.40m\n",
      " 111     4.32      2.22352e+10        3         0.247676         0.258666      8.01m\n",
      " 112     3.64          5466.54        3         0.247307         0.261986      7.11m\n",
      " 113     3.62           798868        3         0.247557         0.259731      7.24m\n",
      " 114     3.64      1.17245e+06        3         0.247167         0.263243      7.01m\n",
      " 115     3.51      6.19643e+06        3         0.247577         0.259552      6.81m\n",
      " 116     3.75            42438        3         0.247084         0.263989      7.49m\n",
      " 117     4.59      7.72695e+17        3         0.247376         0.261363      6.71m\n",
      " 118     3.64      3.14971e+10        4         0.246917         0.265492      7.17m\n",
      " 119     3.42           146993        3         0.247432         0.260859      7.58m\n",
      " 120     3.71          23418.6        3         0.247326         0.261812      6.48m\n",
      " 121     3.47          11797.2        4         0.247474         0.260477      6.80m\n",
      " 122     3.72      1.32585e+08        4         0.247381         0.261319      6.40m\n",
      " 123     5.98      8.05948e+06        3         0.247131          0.26357      7.42m\n",
      " 124     3.99      4.49218e+09        3         0.247434         0.260837      8.08m\n",
      " 125     3.98      5.12209e+11        4         0.247086         0.263974      6.36m\n",
      " 126     3.29          25818.6        3         0.247553          0.25977      6.76m\n",
      " 127     5.25      7.94707e+14        3         0.247232          0.26266      6.20m\n",
      " 128     3.61          3851.25        3         0.247598         0.259362      5.91m\n",
      " 129     5.01      8.86984e+11        3         0.246901         0.265634      6.65m\n",
      " 130     3.47           224013        3         0.247125         0.263616      5.79m\n",
      " 131     3.50          19756.9        4         0.247202          0.26293      6.44m\n",
      " 132     4.67      9.25872e+06        5          0.24702         0.264565      5.80m\n",
      " 133     5.08      2.02064e+07        4         0.247455         0.260652      7.31m\n",
      " 134     6.17      1.03415e+16        3         0.247498         0.260266      5.52m\n",
      " 135     4.25      5.12141e+09        4         0.247647         0.258925      6.63m\n",
      " 136     5.02      6.79639e+07        5         0.247291         0.262122      5.23m\n",
      " 137     4.68      6.12792e+07        4         0.247139         0.263492      5.60m\n",
      " 138     4.43      4.23277e+06        4         0.247579         0.259539      5.43m\n",
      " 139     3.95          800.392        4         0.247455         0.260649      5.45m\n",
      " 140     4.52          7359.13        5         0.247367          0.26144      5.34m\n",
      " 141     5.06          25537.8        3         0.247392         0.261213      6.42m\n",
      " 142     5.37      7.51828e+08        4         0.247279         0.262232      5.78m\n",
      " 143     5.54      4.11295e+07        4         0.247355         0.261548      5.67m\n",
      " 144     5.25      1.97913e+18        3         0.247577         0.259554      5.57m\n",
      " 145     4.15      1.37728e+11        4         0.247544         0.259846      4.96m\n",
      " 146     3.66          5427.63        4         0.247244         0.262549      4.48m\n",
      " 147     4.45          1465.86        3         0.247379         0.261331      4.85m\n",
      " 148     4.21          7756.91        4         0.246974         0.264975      4.36m\n",
      " 149     4.09      8.43732e+07        4          0.24718         0.263127      4.40m\n",
      " 150     4.16      4.72792e+19        3         0.247315         0.261912      4.16m\n",
      " 151     3.95      4.43789e+08        3         0.247239         0.262591      4.26m\n",
      " 152     4.11      1.23888e+09        4         0.246763          0.26688      4.34m\n",
      " 153     4.01      1.56108e+08        4         0.247216         0.262804      4.29m\n",
      " 154     4.29      6.24832e+07        4         0.247239         0.262593      3.87m\n",
      " 155     7.44      1.51595e+11        5         0.247157         0.263331      3.93m\n",
      " 156     3.97      2.38953e+07        5         0.247429         0.260883      4.11m\n",
      " 157     4.32           702329        7         0.247403         0.261121      3.80m\n",
      " 158     4.31      2.69978e+07        3         0.247721         0.258257      3.76m\n",
      " 159     4.28      5.08255e+09        3         0.247409         0.261065      3.79m\n",
      " 160     4.34      3.59373e+06        3         0.247383         0.261297      4.12m\n",
      " 161     4.93      1.41252e+10        4         0.247616         0.259201      4.15m\n",
      " 162     4.09          560.294        5         0.247646         0.258932      3.36m\n",
      " 163     4.09      4.83772e+08        3         0.247343         0.261659      3.42m\n",
      " 164     6.27      4.43682e+08        3         0.247581         0.259518      3.08m\n",
      " 165     3.44          10852.9        3         0.247313         0.261925      3.28m\n",
      " 166     4.11           138340        3         0.247373         0.261393      2.86m\n",
      " 167     4.71          42760.2        3          0.24726         0.262402      2.80m\n",
      " 168     6.02      3.90185e+08        4         0.247489         0.260346      2.98m\n",
      " 169     3.61          5989.02        3         0.247357         0.261533      2.69m\n",
      " 170     3.86      2.19833e+13        3          0.24716         0.263305      2.79m\n",
      " 171     3.12           493771        3          0.24743         0.260875      2.45m\n",
      " 172     3.16          8045.89        3         0.247282         0.262205      2.21m\n",
      " 173     5.60      1.43748e+16        3         0.247505         0.260202      2.46m\n",
      " 174     3.33           327238        3         0.247327         0.261801      2.02m\n",
      " 175     5.10      3.48026e+07        3          0.24748         0.260426      2.45m\n",
      " 176     3.26           279521        3         0.247396         0.261182      1.91m\n",
      " 177     3.44      2.36873e+07        3         0.247168         0.263232      2.11m\n",
      " 178     4.06          30246.6        3         0.246897         0.265674      1.80m\n",
      " 179     3.40      1.67161e+06        3         0.247145         0.263436      2.15m\n",
      " 180     4.18      4.70246e+06        3         0.247553         0.259768      1.86m\n",
      " 181     3.41            73822        3         0.247542         0.259863      1.51m\n",
      " 182     3.75      1.15598e+09        3         0.247202         0.262925      1.39m\n",
      " 183    27.51      1.06838e+28        3         0.247556         0.259739      3.70m\n",
      " 184     4.80      5.75553e+13        3         0.247423         0.260937      1.56m\n",
      " 185     3.41      2.70873e+08        3         0.247608         0.259277      1.11m\n",
      " 186     4.92      7.11823e+10        3         0.246824         0.266333      1.22m\n",
      " 187     3.42           466649        3          0.24711         0.263754      1.22m\n",
      " 188     3.91      1.34718e+08        3         0.247422         0.260943     55.77s\n",
      " 189     3.14          26279.7        3         0.247694         0.258499     55.83s\n",
      " 190     3.34      1.85355e+09        3         0.247105         0.263799     53.16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 191     6.15       8.7805e+15        3         0.247141         0.263477     41.01s\n",
      " 192     3.76            34520        3         0.247429         0.260885     36.28s\n",
      " 193     3.70      8.22635e+09        3         0.247304         0.262007     31.38s\n",
      " 194     4.06      4.53631e+14        3         0.247425         0.260916     24.58s\n",
      " 195     3.50      1.93722e+06        3         0.247291         0.262124     21.31s\n",
      " 196     3.84      1.27533e+10        3         0.247492         0.260319     15.42s\n",
      " 197     4.99       1.2085e+17        3         0.247555         0.259747     10.41s\n",
      " 198     3.38          13544.2        3         0.247294           0.2621      4.80s\n",
      " 199     3.31      3.36352e+07        3         0.246721          0.26726      0.00s\n",
      "train: -5.679344274867049e-07\n",
      "test: -5.3052601136638344e-06\n",
      "train: 0.3875745943169553\n",
      "test: 0.38908158095052214\n",
      "program: sub(X21, X21)\n"
     ]
    }
   ],
   "source": [
    "est_gp = SymbolicRegressor(population_size=500,\n",
    "                           tournament_size=20,\n",
    "                           generations=200, stopping_criteria=0.001,\n",
    "                           const_range=(-3, 3),\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.12,\n",
    "                           p_hoist_mutation=0.06, p_point_mutation=0.12,\n",
    "                           p_point_replace=1,\n",
    "                           init_depth = (10, 18),\n",
    "                           function_set=('mul', 'sub', 'div', 'add', 'sin'),\n",
    "#                            function_set=('mul', 'sub', 'add', 'sin'),\n",
    "                           max_samples=0.9, \n",
    "                           verbose=1,\n",
    "                           metric='mse',\n",
    "                           parsimony_coefficient=0.00001, \n",
    "                           random_state=0, \n",
    "                           n_jobs=20)\n",
    "\n",
    "est_gp.fit(X_train, y_train)\n",
    "print('train:', r2_score(y_train, est_gp.predict(X_train)))\n",
    "print('test:', r2_score(y_test, est_gp.predict(X_test)))\n",
    "print('train:', MAE(y_train, est_gp.predict(X_train)))\n",
    "print('test:', MAE(y_test, est_gp.predict(X_test)))\n",
    "print('program:', est_gp._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.4700183706720499\n",
      "test: 0.46690029553763723\n",
      "train: 0.28775375337821785\n",
      "test: 0.289285949988508\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(0.001)\n",
    "model.fit(X_train, y_train)\n",
    "print('train:', r2_score(y_train, model.predict(X_train)))\n",
    "print('test:', r2_score(y_test, model.predict(X_test)))\n",
    "print('train:', MAE(y_train, model.predict(X_train)))\n",
    "print('test:', MAE(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_gp = SymbolicRegressor(population_size=500,\n",
    "                           tournament_size=20,\n",
    "                           generations=100, stopping_criteria=0.01,\n",
    "                           const_range=(-1, 1),\n",
    "                           p_crossover=0.5, p_subtree_mutation=0.22,\n",
    "                           p_hoist_mutation=0.06, p_point_mutation=0.22,\n",
    "                           p_point_replace=1,\n",
    "                           init_depth = (5, 10),\n",
    "                           function_set=('mul', 'sub', 'div', 'add', 'sin'),\n",
    "                           max_samples=0.9, \n",
    "                           verbose=1,\n",
    "                           parsimony_coefficient=0.00001, \n",
    "                           random_state=0, \n",
    "                           n_jobs=20)\n",
    "\n",
    "est_gp.fit(x, y)\n",
    "print('program:', est_gp._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
