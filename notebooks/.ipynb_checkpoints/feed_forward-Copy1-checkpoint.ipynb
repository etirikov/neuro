{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mens = []\n",
    "womens = []\n",
    "labels = pd.read_csv('./gender_labels.csv')\n",
    "for s in glob.glob('/neuro/notebooks/all_data_confounds_remove/*.csv'):\n",
    "    person = int(s.split('/')[-1].split('_')[0])\n",
    "    data = pd.read_csv(s)\n",
    "    data = data.rolling(window=10).mean().dropna()\n",
    "    if labels[labels['person']==person]['gender'].values[0]=='M':\n",
    "        mens.append(data)\n",
    "    else:\n",
    "        womens.append(data)\n",
    "mens = pd.concat(mens)\n",
    "womens = pd.concat(womens)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../notebooks/filter_with_confounds_dataset.csv')\n",
    "# data = mens\n",
    "# region = 'x1'\n",
    "# X = data.drop([region], axis=1).values\n",
    "# y = data[region].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147684, 48)\n",
      "x41\n",
      "Iteration: 0\n",
      "train: -4.368909272123169\n",
      "test: -4.49113944695885\n",
      "train: 0.27695844880522025\n",
      "test: 0.28170401002928924\n",
      "Iteration: 2000\n",
      "train: 0.9196575221704893\n",
      "test: 0.8569303294267646\n",
      "train: 0.0334324030762009\n",
      "test: 0.05973448594099765\n",
      "Iteration: 4000\n",
      "train: 0.9201842444042457\n",
      "test: 0.8484023689157463\n",
      "train: 0.032849639256478186\n",
      "test: 0.06279730958215812\n",
      "Iteration: 6000\n",
      "train: 0.9167089256208378\n",
      "test: 0.8423334585385535\n",
      "train: 0.03412402047278984\n",
      "test: 0.06491872583541515\n",
      "Iteration: 8000\n",
      "train: 0.9196468609571904\n",
      "test: 0.8443493100658603\n",
      "train: 0.033350282218913785\n",
      "test: 0.06481518514991932\n",
      "x42\n",
      "Iteration: 0\n",
      "train: -19.27966888809776\n",
      "test: -19.629709694039565\n",
      "train: 0.32407144347497846\n",
      "test: 0.32856965092242313\n",
      "Iteration: 2000\n",
      "train: 0.8755277769120948\n",
      "test: 0.7869351932050086\n",
      "train: 0.046188556544344034\n",
      "test: 0.07947832585777491\n",
      "Iteration: 4000\n",
      "train: 0.8838468050793087\n",
      "test: 0.7808903833078038\n",
      "train: 0.04246045068019806\n",
      "test: 0.08080550705802293\n",
      "Iteration: 6000\n",
      "train: 0.8802431864978671\n",
      "test: 0.7747509081876887\n",
      "train: 0.04315988351809858\n",
      "test: 0.08193103980322203\n",
      "Iteration: 8000\n",
      "train: 0.8823962558105628\n",
      "test: 0.7749029079650294\n",
      "train: 0.042771345284523955\n",
      "test: 0.08267341297774598\n",
      "x43\n",
      "Iteration: 0\n",
      "train: -45.88610282859454\n",
      "test: -45.749110987544164\n",
      "train: 0.2737503340487513\n",
      "test: 0.2720765103337761\n",
      "Iteration: 2000\n",
      "train: 0.8205222960865773\n",
      "test: 0.6748116412045866\n",
      "train: 0.04420734764874884\n",
      "test: 0.07930725142643709\n",
      "Iteration: 4000\n",
      "train: 0.8295235420171101\n",
      "test: 0.6714634641464339\n",
      "train: 0.04268402213715812\n",
      "test: 0.08180183306659941\n",
      "Iteration: 6000\n",
      "train: 0.8353785894249691\n",
      "test: 0.6749861673628558\n",
      "train: 0.04201400477007031\n",
      "test: 0.08242799209032195\n",
      "Iteration: 8000\n",
      "train: 0.8308857464050027\n",
      "test: 0.6655631551562988\n",
      "train: 0.0424549926812429\n",
      "test: 0.08331353501381829\n",
      "x44\n",
      "Iteration: 0\n",
      "train: -341.01905303761646\n",
      "test: -345.7723901770674\n",
      "train: 0.2665374491840352\n",
      "test: 0.26739080009480054\n",
      "Iteration: 2000\n",
      "train: 0.8291049911620985\n",
      "test: 0.6971840377459652\n",
      "train: 0.0408446028925056\n",
      "test: 0.07153937132732646\n",
      "Iteration: 4000\n",
      "train: 0.8381434034962132\n",
      "test: 0.6964320409000446\n",
      "train: 0.03897367544296813\n",
      "test: 0.07245487399609445\n",
      "Iteration: 6000\n",
      "train: 0.8471268299096938\n",
      "test: 0.6994049142865382\n",
      "train: 0.03815363686417659\n",
      "test: 0.07439857542859224\n",
      "Iteration: 8000\n",
      "train: 0.842567621507258\n",
      "test: 0.6899481784986727\n",
      "train: 0.03782919644291818\n",
      "test: 0.07377125274422246\n",
      "x45\n",
      "Iteration: 0\n",
      "train: -26.684505489690725\n",
      "test: -26.807816562902392\n",
      "train: 0.34006557199738385\n",
      "test: 0.3403579371937238\n",
      "Iteration: 2000\n",
      "train: 0.8957476180504431\n",
      "test: 0.8144649006843557\n",
      "train: 0.035241912641865325\n",
      "test: 0.062443270084730246\n",
      "Iteration: 4000\n",
      "train: 0.897629575467593\n",
      "test: 0.8147292280088714\n",
      "train: 0.03564893901208975\n",
      "test: 0.0642908292779971\n",
      "Iteration: 6000\n",
      "train: 0.8993011088483938\n",
      "test: 0.8088764662892416\n",
      "train: 0.034969508127839104\n",
      "test: 0.06627988872377974\n",
      "Iteration: 8000\n",
      "train: 0.8974485050574338\n",
      "test: 0.8059142977625737\n",
      "train: 0.03510374763040585\n",
      "test: 0.06641603625691936\n",
      "x46\n",
      "Iteration: 0\n",
      "train: -99.16265688152937\n",
      "test: -98.85180519404571\n",
      "train: 0.36074482758916515\n",
      "test: 0.35846284485443763\n",
      "Iteration: 2000\n",
      "train: 0.9121221179157271\n",
      "test: 0.8406729924868676\n",
      "train: 0.029861223047290303\n",
      "test: 0.053898601106497905\n",
      "Iteration: 4000\n",
      "train: 0.9120278842190797\n",
      "test: 0.8340033656256403\n",
      "train: 0.02990990668904674\n",
      "test: 0.056153268763734936\n",
      "Iteration: 6000\n",
      "train: 0.9121472605504748\n",
      "test: 0.8314219839344741\n",
      "train: 0.030087516523099208\n",
      "test: 0.05757134934884337\n",
      "Iteration: 8000\n",
      "train: 0.9141585312553376\n",
      "test: 0.829600367722155\n",
      "train: 0.02938796176416219\n",
      "test: 0.05822520580215974\n",
      "x47\n",
      "Iteration: 0\n",
      "train: -56.582972656148876\n",
      "test: -56.00656549362506\n",
      "train: 0.5247386486629767\n",
      "test: 0.5232544477217396\n",
      "Iteration: 2000\n",
      "train: 0.8266752272038207\n",
      "test: 0.6792037429529184\n",
      "train: 0.08332373699621536\n",
      "test: 0.15215955935024406\n",
      "Iteration: 4000\n",
      "train: 0.8247776719834468\n",
      "test: 0.6611860885185723\n",
      "train: 0.08330353305850288\n",
      "test: 0.1590898892577419\n",
      "Iteration: 6000\n",
      "train: 0.8225675938601564\n",
      "test: 0.6501471274804005\n",
      "train: 0.08270553540953797\n",
      "test: 0.1612695034817556\n",
      "Iteration: 8000\n",
      "train: 0.8256468205505543\n",
      "test: 0.6510773205836669\n",
      "train: 0.08268428231974036\n",
      "test: 0.1642050582433417\n"
     ]
    }
   ],
   "source": [
    "loses_by_epoch = {}\n",
    "data = mens\n",
    "print(data.shape)\n",
    "for i in range(41, 48):\n",
    "    region = 'x'+str(i)\n",
    "    print(region)\n",
    "    loses_by_epoch[region] = list()\n",
    "    X = data.drop([region], axis=1).values\n",
    "    y = data[region].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "\n",
    "    N, D_in, H, D_out = 64, 1000, 2, 10\n",
    "    device='cuda:2'\n",
    "    X_train_torch = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_torch = torch.FloatTensor(y_train).to(device)\n",
    "\n",
    "    X_test_torch = torch.FloatTensor(X_test).to(device)\n",
    "    y_test_torch = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(47, 100),\n",
    "        torch.nn.Softplus(),\n",
    "        torch.nn.Linear(100, 50),\n",
    "        torch.nn.Softplus(),\n",
    "        torch.nn.Linear(50, 25),\n",
    "        torch.nn.Tanh(),\n",
    "        torch.nn.Linear(25, 1),\n",
    "    ).to(device)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    learning_rate = 1e-2\n",
    "    batch_size = 8096\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for t in range(10000):\n",
    "        for batch in range(0, X_train.shape[0], batch_size):\n",
    "\n",
    "            y_pred_train = model(X_train_torch[batch:batch+batch_size])\n",
    "\n",
    "\n",
    "            loss_train = loss_fn(y_pred_train, y_train_torch.reshape(-1, 1)[batch:batch+batch_size])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_predict = model(X_train_torch).detach().cpu().numpy()\n",
    "        test_predict = model(X_test_torch).detach().cpu().numpy()\n",
    "        r2_train = r2_score(np.ravel(train_predict), np.ravel(y_train))\n",
    "        r2_test = r2_score(np.ravel(test_predict), np.ravel(y_test))\n",
    "        mse_train = mean_squared_error(np.ravel(train_predict), np.ravel(y_train))\n",
    "        mse_test = mean_squared_error(np.ravel(test_predict), np.ravel(y_test))\n",
    "        loses_by_epoch[region].append([r2_train, r2_test, mse_train, mse_test])\n",
    "        if t%2000==0:\n",
    "            print('Iteration:',t)\n",
    "            print('train:',r2_score(np.ravel(train_predict), np.ravel(y_train)))\n",
    "            print('test:',r2_score(np.ravel(test_predict), np.ravel(y_test)))\n",
    "            print('train:',mean_squared_error(np.ravel(train_predict), np.ravel(y_train)))\n",
    "            print('test:',mean_squared_error(np.ravel(test_predict), np.ravel(y_test)))\n",
    "    torch.save(model.state_dict(), './models/pytorch_model_{0}_mens.pt'.format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
